{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcus/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pyntcloud import PyntCloud\n",
    "from modelnet import *\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ModelNet 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the ModelNet data loader\n",
    "modelnet = ModelNet(shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: tv_stand\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f278e9501d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a random point cloud from the training data\n",
    "index = np.random.randint(modelnet.train.num_examples)\n",
    "\n",
    "# Print categry name\n",
    "print(\"Category:\", modelnet.categories[np.argmax(modelnet.train._labels[index])])\n",
    "\n",
    "# Show xyz axis\n",
    "axis = [\n",
    "    [[0, 0, 0], [1, 0, 0]],\n",
    "    [[0, 0, 0], [0, 1, 0]],\n",
    "    [[0, 0, 0], [0, 0, 1]],\n",
    "]\n",
    "\n",
    "# Show point cloud\n",
    "PyntCloud(pd.DataFrame(modelnet.train._points[index], columns=[\"x\", \"y\", \"z\"])).plot(point_size=0.01, opacity=1.0, lines=axis, line_color=[0xFF0000, 0x00FF00, 0x0000FF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate 90 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f279da886a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################\n",
    "# def rotate\n",
    "# Rotates one or a batch of point clouds along the up-axiz (y)\n",
    "###############################################################\n",
    "def rotate(points, theta):\n",
    "    if points.ndim == 2: points = np.expand_dims(points, axis=0)   \n",
    "    rotation_matrix = np.array([[ np.cos(theta), 0, np.sin(theta)],\n",
    "                                [ 0,             1,             0],\n",
    "                                [-np.sin(theta), 0, np.cos(theta)]])\n",
    "    rotation_matrix = np.expand_dims(rotation_matrix, axis=0)\n",
    "    rotation_matrix  = np.repeat(rotation_matrix, len(points), axis=0)\n",
    "    return np.matmul(points, rotation_matrix)\n",
    "\n",
    "# Show point cloud\n",
    "PyntCloud(pd.DataFrame(np.squeeze(rotate(modelnet.train._points[index], np.pi/2.0), axis=0), columns=[\"x\", \"y\", \"z\"])).plot(point_size=0.01, opacity=1.0, lines=axis, line_color=[0xFF0000, 0x00FF00, 0x0000FF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jitter the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f278e9ef668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################\n",
    "# def rotate\n",
    "# Jitter one or a batch of point clouds by adding\n",
    "# gaussian noise to the xyz components\n",
    "###############################################################\n",
    "def jitter(points, mean, std):\n",
    "    return points + np.random.normal(mean, std, points.shape)\n",
    "\n",
    "# Show point cloud\n",
    "PyntCloud(pd.DataFrame(jitter(modelnet.train._points[index], 0.0, 0.02), columns=[\"x\", \"y\", \"z\"])).plot(point_size=0.01, opacity=1.0, lines=axis, line_color=[0xFF0000, 0x00FF00, 0x0000FF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PointNet](PointNet-Architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Point cloud placeholder -> [batch_size x num_points x 3]\n",
    "points = tf.placeholder(tf.float32, [None, modelnet.num_points, 3])\n",
    "labels = tf.placeholder(tf.float32, [None, modelnet.num_categories])\n",
    "batch_norm_decay = tf.placeholder(tf.float32)\n",
    "dropout_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "# Points to features -> MLP(64, 64)\n",
    "feat = tf.layers.conv1d(points, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu) # [batch_size x num_points x 64]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "feat = tf.layers.conv1d(feat, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu)   # [batch_size x num_points x 64]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "\n",
    "# Increase num features -> MLP(64, 128, 1024)\n",
    "feat = tf.layers.conv1d(feat, filters=64, kernel_size=1, strides=1, activation=tf.nn.relu)   # [batch_size x num_points x 64]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "feat = tf.layers.conv1d(feat, filters=128, kernel_size=1, strides=1, activation=tf.nn.relu)  # [batch_size x num_points x 128]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "feat = tf.layers.conv1d(feat, filters=1024, kernel_size=1, strides=1, activation=tf.nn.relu) # [batch_size x num_points x 1024]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "\n",
    "# Extract global features -> maxpool\n",
    "feat = tf.reduce_max(feat, 1) # [batch_size x 1024]\n",
    "\n",
    "# Generate predictions -> FC(512, 256, num_categories)\n",
    "feat = tf.layers.dense(feat, units=512, activation=tf.nn.relu) # [batch_size x 512]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "feat = tf.layers.dense(feat, units=256, activation=tf.nn.relu) # [batch_size x 256]\n",
    "feat = tf.contrib.layers.batch_norm(feat, decay=batch_norm_decay)\n",
    "feat = tf.layers.dropout(feat, rate=dropout_rate) # Dropout with keep rate 0.7 = 1.0 - 0.3\n",
    "feat = tf.layers.dense(feat, units=modelnet.num_categories, activation=None) # [batch_size x num_categories]\n",
    "\n",
    "# Cross entropy softmax loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=feat, labels=labels))\n",
    "\n",
    "# Get predicted classes\n",
    "predictions = tf.argmax(tf.nn.softmax(feat), axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_labels = tf.equal(predictions, tf.argmax(labels, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_labels, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for learning rate (used in training loop)\n",
    "learning_rate = tf.placeholder(tf.float32, [], name=\"learning_rate\")\n",
    "\n",
    "# Initialize AdamOptimizer\n",
    "optim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Create session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Label, Box\n",
    "from IPython.display import display\n",
    "\n",
    "statusLabel = Label(\"\")\n",
    "display(Box([statusLabel]))\n",
    "\n",
    "# Make batches to train\n",
    "batch_size = 32\n",
    "current_epoch = 0\n",
    "current_learning_rate = 0.001\n",
    "current_bn_decay = 0.5\n",
    "current_loss = 0\n",
    "current_test_accuracy = 0\n",
    "num_iter = 0\n",
    "start_time = time.time()\n",
    "epoch_time = 0\n",
    "\n",
    "# Try to load model file if epoch is specified\n",
    "if current_epoch != 0:\n",
    "    saver = tf.train.import_meta_graph(\"models/PointNet_Vanilla-%i.meta\" % current_epoch)\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\"./models\"))\n",
    "    current_learning_rate /= np.power(2, current_epoch // 20)\n",
    "    stats = load_object(\"stats/PointNet_Vanilla.stats\")\n",
    "else:\n",
    "    saver = tf.train.Saver()\n",
    "    stats = { key: [] for key in [\"loss\", \"accuracy\"] }\n",
    "\n",
    "while True:\n",
    "    # If epoch of training data is complete\n",
    "    if modelnet.train.is_epoch_complete():\n",
    "        # Measure time\n",
    "        epoch_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Avg loss\n",
    "        current_loss /= num_iter\n",
    "        \n",
    "        # Calculate accuracy on test set\n",
    "        num_iter = 0\n",
    "        current_test_accuracy = 0\n",
    "        epoch_complete = False\n",
    "        while not modelnet.test.is_epoch_complete():\n",
    "            batch_points, batch_labels = modelnet.test.next_batch(batch_size)\n",
    "            current_test_accuracy += sess.run(accuracy, feed_dict={points: batch_points,\n",
    "                                                                   labels: batch_labels,\n",
    "                                                                   dropout_rate: 0.0})\n",
    "            num_iter += 1\n",
    "        current_test_accuracy /= num_iter\n",
    "            \n",
    "        \n",
    "        # Save best model\n",
    "        if current_epoch == 0 or current_test_accuracy > np.max(stats[\"accuracy\"]):\n",
    "            saver.save(sess, \"models/PointNet_Vanilla-best\")\n",
    "            save_object(stats, \"stats/PointNet_Vanilla.stats\")\n",
    "            \n",
    "        # Increase epoch count\n",
    "        current_epoch += 1\n",
    "        \n",
    "        # Append some stats\n",
    "        stats[\"loss\"].append(current_loss)\n",
    "        stats[\"accuracy\"].append(current_test_accuracy)\n",
    "        \n",
    "        # Every 20th epoch, halve the learning rate\n",
    "        if current_epoch % 20 == 0:\n",
    "            # Save the model\n",
    "            saver.save(sess, \"models/PointNet_Vanilla\", global_step=current_epoch)\n",
    "            save_object(stats, \"stats/PointNet_Vanilla.stats\")\n",
    "            \n",
    "            # Halve the learning rate\n",
    "            current_learning_rate /= 2.0\n",
    "            \n",
    "        # Interpolate decay rate from 0.5 to 0.99 over 80 epochs\n",
    "        current_bn_decay = lerp(0.5, 0.99, np.min([current_epoch / 80, 1.0]))\n",
    "        \n",
    "        # Display training status\n",
    "        statusSting  = \"[Epoch %i] \" % current_epoch\n",
    "        statusSting += \"Time: %im %is; \" % (epoch_time // 60, epoch_time % 60)\n",
    "        statusSting += \"Loss: %f; \" % current_loss\n",
    "        statusSting += \"Learning rate: %f; \" % current_learning_rate\n",
    "        statusSting += \"BN decay rate: %f; \" % current_bn_decay\n",
    "        statusSting += \"Accuracy: %f; \" % current_test_accuracy\n",
    "        statusSting += \"--- \";\n",
    "        statusSting += \"Current best: [Epoch %i] \" % np.argmax(stats[\"accuracy\"])\n",
    "        statusSting += \"Accuracy %f; \" % np.max(stats[\"accuracy\"])\n",
    "        statusLabel.value = statusSting\n",
    "        \n",
    "        # Reset loss\n",
    "        current_loss = 0\n",
    "        num_iter = 0\n",
    "    \n",
    "    # Get next batch\n",
    "    batch_points, batch_labels = modelnet.train.next_batch(batch_size)\n",
    "    \n",
    "    # Rotate 10% of the time\n",
    "    if np.random.rand() < 0.1:\n",
    "        batch_points = rotate(batch_points, np.pi * np.random.choice([1.0 / 2.0, 1.0, 3.0 / 2.0]))\n",
    "    \n",
    "    # Jitter 25% of the time\n",
    "    if np.random.rand() < 0.25:\n",
    "        batch_points = jitter(batch_points, 0.0, 0.02)\n",
    "    \n",
    "    # Do training\n",
    "    current_loss += sess.run([optim, loss], feed_dict={points: batch_points,\n",
    "                                                       labels: batch_labels,\n",
    "                                                       learning_rate: current_learning_rate,\n",
    "                                                       batch_norm_decay: current_bn_decay,\n",
    "                                                       dropout_rate: 0.3})[1]\n",
    "    num_iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best results\n",
    "[Epoch 262] Accuracy 0.884615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(stats[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(stats[\"accuracy\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
