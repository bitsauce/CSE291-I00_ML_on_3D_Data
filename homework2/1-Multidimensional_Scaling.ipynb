{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Importing Libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Read Data\n",
    "data = input_data.read_data_sets(\"MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = [[] for i in range(10)]\n",
    "for image, label in zip(data.train.images, data.train.labels):\n",
    "    label = np.argmax(label)\n",
    "    if len(samples[label]) < 10: # 1000:\n",
    "        samples[label].append(image)\n",
    "samples = [image for s in samples for image in s] # flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "N = len(samples)\n",
    "D = distance_matrix(samples, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for input image \n",
    "img = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# Variable X\n",
    "X_prime = tf.get_variable(\"X\", initializer=tf.random_normal((N, 2), -1.0, 1.0))\n",
    "\n",
    "# Calculate D prime\n",
    "loss = 0\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        D_prime = tf.sqrt(tf.pow(tf.reduce_sum(X_prime[i] - X_prime[j]), 2))\n",
    "        loss += tf.pow(D_prime - D[i, j], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Optimizer\n",
    "optim = tf.train.AdamOptimizer(learning_rate=0.0000001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Make batches to train\n",
    "num_iter = 1\n",
    "batch_size = 100\n",
    "for i in range(num_iter):\n",
    "    batch_img = samples[i*batch_size:(i+1)*batch_size] # data.train.next_batch(batch_size)\n",
    "    _, l, x = sess.run([optim, loss, X], feed_dict = {img: batch_img})\n",
    "    print(l, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
